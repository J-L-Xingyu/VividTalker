import torch
import soundfile as sf
import asyncio
import time
from transformers import AutoTokenizer
from diffusers import StableDiffusion3Pipeline
from parler_tts import ParlerTTSForConditionalGeneration

# è®¾ç½®éšæœºç§å­
torch.random.manual_seed(0)

# æ¨¡å‹è·¯å¾„
tts_model_path = "/share/home/liuxingy/real3dportrait/models/parler_tts_mini_v0.1"
image_model_path = "/share/home/liuxingy/real3dportrait/models/stable-diffusion-3-medium-diffusers"

# 1ï¸âƒ£ **åŠ è½½ TTS æ¨¡å‹**
tts_tokenizer = AutoTokenizer.from_pretrained(tts_model_path)
tts_model = ParlerTTSForConditionalGeneration.from_pretrained(tts_model_path).to("cuda:2")

# 2ï¸âƒ£ **åŠ è½½ Stable Diffusion 3 å›¾åƒç”Ÿæˆæ¨¡å‹**
pipe = StableDiffusion3Pipeline.from_pretrained(image_model_path, torch_dtype=torch.float16)
pipe = pipe.to("cuda:1")
pipe.enable_attention_slicing("auto")  # ä¼˜åŒ–æ˜¾å­˜å ç”¨

def generate_image(prompt):
    image = pipe(prompt).images[0]
    image_path = "/share/home/liuxingy/2/data/picture/image_5.png"
    image.save(image_path)
    return image_path

# 3ï¸âƒ£ **å¼‚æ­¥éŸ³é¢‘ç”Ÿæˆ**
async def generate_audio(prompt, speaker_description, idx):
    """å¼‚æ­¥ç”ŸæˆéŸ³é¢‘ï¼Œå¹¶è®°å½•æ—¶é—´"""
    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´

    input_ids = tts_tokenizer(speaker_description, return_tensors="pt").input_ids.to("cuda:2")
    prompt_input_ids = tts_tokenizer(prompt, return_tensors="pt").input_ids.to("cuda:2")

    loop = asyncio.get_running_loop()
    generation = await loop.run_in_executor(None, lambda: tts_model.generate(input_ids=input_ids,
                                                                             prompt_input_ids=prompt_input_ids))

    audio_arr = generation.cpu().numpy().squeeze()

    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    audio_path = f"/share/home/liuxingy/2/data/audio/audio_{idx + 1}.wav"
    sf.write(audio_path, audio_arr, tts_model.config.sampling_rate)

    end_time = time.time()  # è®°å½•ç»“æŸæ—¶é—´
    print(f"[TTS] éŸ³é¢‘ç”Ÿæˆæ—¶é—´: {end_time - start_time:.2f} ç§’")

    return audio_path, end_time - start_time


# 4ï¸âƒ£ **å¼‚æ­¥å›¾åƒç”Ÿæˆ**
# async def generate_image(prompt, idx):
#     """å¼‚æ­¥ç”Ÿæˆå›¾åƒï¼Œå¹¶è®°å½•æ—¶é—´"""
#     start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
#
#     new_prompt = prompt
#
#     loop = asyncio.get_running_loop()
#     image = await loop.run_in_executor(None,
#                                        lambda: pipe(new_prompt, num_inference_steps=20, guidance_scale=7.0).images[0])
#
#     image_path = f"/share/home/liuxingy/2/data/picture/image_{idx + 1}.png"
#     image.save(image_path)
#
#     end_time = time.time()  # è®°å½•ç»“æŸæ—¶é—´
#     print(f"[SD] å›¾åƒç”Ÿæˆæ—¶é—´: {end_time - start_time:.2f} ç§’")
#
#     return image_path, end_time - start_time


# 5ï¸âƒ£ **å¹¶è¡Œæ‰§è¡Œ TTS & SD**
async def generate_media(photo_prompt, tts_prompt, speaker, idx):
    """
    å¹¶è¡Œç”ŸæˆéŸ³é¢‘å’Œå›¾åƒï¼Œå¹¶è®°å½•æ€»æ—¶é—´
    :return: ç”Ÿæˆçš„å›¾åƒå’ŒéŸ³é¢‘æ–‡ä»¶è·¯å¾„, ä»¥åŠæ‰§è¡Œæ—¶é—´
    """
    total_start_time = time.time()  # è®°å½•æ€»å¼€å§‹æ—¶é—´

    image_task = asyncio.create_task(generate_image(photo_prompt, idx))
    audio_task = asyncio.create_task(generate_audio(tts_prompt, speaker, idx))

    image_path, image_time = await image_task
    audio_path, audio_time = await audio_task

    total_end_time = time.time()  # è®°å½•æ€»ç»“æŸæ—¶é—´
    total_time = total_end_time - total_start_time

    print(f"ğŸŒŸ [æ€»è®¡] TTS + SD å¹¶è¡Œè¿è¡Œæ—¶é—´: {total_time:.2f} ç§’")
    print(f"âš¡ [ä¸²è¡Œé¢„ä¼°] TTS + SD é¢„è®¡æ—¶é—´: {image_time + audio_time:.2f} ç§’")

    return image_path, audio_path, total_time

photo_description = "A high-resolution, well-lit frontal portrait of a professional woman in formal attire, seated behind a news desk with a microphone. She has a confident expression, with even lighting and a neutral studio background."
generate_image(photo_description)