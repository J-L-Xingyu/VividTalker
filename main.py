import asyncio
from analyse import analyze_task, analyze_speech_edit  # è°ƒç”¨ LM è§£æä»»åŠ¡
from vision_audio import generate_media  # è°ƒç”¨ SD & TTS ç”Ÿæˆå›¾åƒ & éŸ³é¢‘
from video_generation import generate_final_video
from edit_analyze import classify_edit_request
from edit_handler import handle_incremental_edit


async def main():
    # 1ï¸âƒ£ **ç”¨æˆ·è¾“å…¥**
    user_description = "a bride reciting her wedding vows"

    # 2ï¸âƒ£ **è§£æç”¨æˆ·è¾“å…¥ï¼Œè·å– Photo & TTS è¯­éŸ³æè¿°**
    print("ğŸš€ [1] è§£æç”¨æˆ·è¾“å…¥...")
    task_info, analyse_time = analyze_task(user_description)  # è§£æä»»åŠ¡
    original_task_info = task_info  # âœ… ç¡®ä¿ task_info ä¼ é€’åˆ° `handle_incremental_edit()`

    photo_description = task_info["Photo"]
    tts_prompt = task_info["TTS Prompt"]
    speaker_description = task_info["Speaker"]

    print("âœ… è§£æå®Œæˆï¼Œç”Ÿæˆçš„ä»»åŠ¡ä¿¡æ¯ï¼š")
    print(f"ğŸ–¼ï¸ [Photo] {photo_description}")
    print(f"ğŸ”Š [TTS Prompt] {tts_prompt}")
    print(f"ğŸ—£ï¸ [Speaker] {speaker_description}")

    # 3ï¸âƒ£ **å¹¶è¡Œç”Ÿæˆå›¾åƒ & éŸ³é¢‘**
    print("ğŸš€ [2] å¹¶è¡Œç”Ÿæˆå›¾åƒ & éŸ³é¢‘...")
    image_path, audio_path, audio_time = await generate_media(photo_description, tts_prompt, speaker_description, idx=1)

    # 4ï¸âƒ£ **ç”Ÿæˆæœ€ç»ˆè§†é¢‘**
    print("ğŸš€ [3] ç”Ÿæˆæœ€ç»ˆè§†é¢‘...")
    video_path, video_time = generate_final_video(image_path, audio_path, idx=3)

    total_time = analyse_time + video_time + audio_time

    print(f"âœ… [4] è§†é¢‘ç”Ÿæˆå®Œæˆï¼Œæ–‡ä»¶è·¯å¾„: {video_path}")
    print(f"âš¡ æ€»è€—æ—¶: {total_time:.2f} ç§’")



# è¿è¡Œ `main.py`
if __name__ == "__main__":
    asyncio.run(main())

#Make the voice deeper